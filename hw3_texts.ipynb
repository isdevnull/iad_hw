{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHgmxWG_7lnE"
   },
   "source": [
    "# Введение в анализ данных\n",
    "## НИУ ВШЭ, 2019-2020 учебный год\n",
    "\n",
    "### Домашнее задание №3\n",
    "\n",
    "Задание выполнил(а): Щекотов Иван\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "__Дата выдачи:__ 08.04.2020\n",
    "\n",
    "__Дедлайн:__ 23:59 22.04.2020\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Оценка за ДЗ вычисляется по следующей формуле:\n",
    "\n",
    "$$\n",
    "\\min(\\text{points}, 21)  \\times 10 / 21,\n",
    "$$\n",
    "\n",
    "где points — количество баллов за домашнее задание, которое вы набрали. Максимальное число баллов, которое можно получить за решение данного домашнего задания — 24, все баллы сверх 21 идут в бонус (таким образом, за данное домашнее задание можно получить 3 бонусных балла). Накопленные бонусные баллы можно будет потом распределять по другим домашним заданиям и проверочным (+1 бонусный балл = +1 к оценке за домашнее задание/проверочную).\n",
    "\n",
    "За сдачу задания позже срока на итоговую оценку за задание накладывается штраф в размере 1 балл в день, но получить отрицательную оценку нельзя.\n",
    "\n",
    "__Внимание!__ Домашнее задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов.\n",
    "\n",
    "### Формат сдачи\n",
    "\n",
    "Загрузка файлов с решениями происходит в системе [Anytask](https://anytask.org/).\n",
    "\n",
    "Инвайт для группы ИАД-4: zG1cIyT\n",
    "\n",
    "Перед отправкой перезагрузите ноутбук и проверьте, что все ячейки могут быть последовательно выполнены. Ноутбук должен запускаться с использованием python 3.6+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ztx03xvr9T95"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVrrwTJNjuDt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# чтобы видеть проход по итерациям, можно использовать библиотеку tqdm\n",
    "# она работает примерно так:\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvXKae8q9nn-"
   },
   "source": [
    "### Данные\n",
    "\n",
    "Мы имеем дело с данными с торговой платформы Avito.\n",
    "Для каждого товара представлены следующие параметры:\n",
    " - `'title'`\n",
    " - `'description'`\n",
    " - `'Category_name'`\n",
    " - `'Category'`\n",
    "\n",
    "Имеется информация об объектах 50 классов.\n",
    "Задача: по новым объектам (`'title'`, `'description'`) предсказать `'Category'`.\n",
    "(Очевидно, что параметр `'Category_name'` для предсказания классов использовать нельзя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "BqEuoDhqNgoa",
    "outputId": "b345f049-ae77-4d1b-a25f-4d4f447e63d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>Category_name</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382220</th>\n",
       "      <td>Прихожая</td>\n",
       "      <td>В хорошем состоянии. Торг</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397529</th>\n",
       "      <td>Кордиант 215/55/16 Летние</td>\n",
       "      <td>Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584569</th>\n",
       "      <td>Стол</td>\n",
       "      <td>Стол, 2 рабочих места . Стол серого цвета, в д...</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513100</th>\n",
       "      <td>Комбинезон</td>\n",
       "      <td>Размер-42/44</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091886</th>\n",
       "      <td>Ветровка</td>\n",
       "      <td>На 2 года</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "id                                   \n",
       "382220                    Прихожая   \n",
       "397529   Кордиант 215/55/16 Летние   \n",
       "584569                        Стол   \n",
       "2513100                 Комбинезон   \n",
       "1091886                   Ветровка   \n",
       "\n",
       "                                               description  \\\n",
       "id                                                           \n",
       "382220                           В хорошем состоянии. Торг   \n",
       "397529   Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...   \n",
       "584569   Стол, 2 рабочих места . Стол серого цвета, в д...   \n",
       "2513100                                       Размер-42/44   \n",
       "1091886                                          На 2 года   \n",
       "\n",
       "                     Category_name  Category  \n",
       "id                                            \n",
       "382220           Мебель и интерьер        20  \n",
       "397529       Запчасти и аксессуары        10  \n",
       "584569           Мебель и интерьер        20  \n",
       "2513100  Одежда, обувь, аксессуары        27  \n",
       "1091886     Детская одежда и обувь        29  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"avito_data.csv\", index_col='id')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Kg8iPp7fiwGh",
    "outputId": "96ed00ed-b63b-4478-f2d4-66bda1110b5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1hvzAMETU2d"
   },
   "outputs": [],
   "source": [
    "X = data[['title', 'description']].to_numpy()\n",
    "y = data['Category'].to_numpy()\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMYU7zZw_cw-"
   },
   "source": [
    "Сразу разделим выборку на train и test.\n",
    "Никакие данные из test для обучения использовать нельзя!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fia4_3vNprp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "qDR8LtTJUIGt",
    "outputId": "fd4d5b55-a023-4129-9ff5-a6e8e24db915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Сапоги 46 размер новые', 'Сапоги 46 размер новые'],\n",
       "       ['Светильники потолочный swarovski',\n",
       "        'светильники потолочные swarovski 6 штук , цена за штуку. В эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n",
       "       ['iPhone 7 plus 128GB Red красный в наличии',\n",
       "        '\\xa0/\\n/\\n Данная цена только для подписчиков Instagram: iQmac/\\n/\\n Новый красный айфон 7 Plus в наличии это элегантный и мощный смартфон, который готов в полной мере раскрыть новые возможности iOS 10. Аппарат с 4-ядерным процессором А10 и 3 ГБ ОЗУ с легкостью решает самые ресурсоемкие задачи, позволяя наслаждаться быстродействием «тяжелых» приложений и игр на 5,5-дюймовом дисплее. Аппарат получил экран, как у iPad Pro, так что картинка теперь соответствует кинематографическому стандарту.'],\n",
       "       ['Пион Ирис Ромашка рассада',\n",
       "        'Пион куст 500 р ( более 10 шт)/\\nСаженец/ корень 100р/\\nРастут у нас более 70 лет/\\nРозовые, бордовые и белые/\\nНа фото цветы 2018г/\\nП. Зубчаниновка/\\nлибо пл. Революции/\\nЕсть ирисы, ромашка, клубника, боярышник и ирга'],\n",
       "       ['Кофта', 'Состояние отличное']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27,  20,  84, 106,  27])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Винт сдвижной панели потолка бмв Х5 Е53',\n",
       "        '\"*3308* Винт сдвижной панели потолка oem: 54107199476 (54 10 7 199 476) /\\n/\\n Запчасть Б/У в хорошем состоянии для BMW X5 E53, /\\nдемонтирована с автомобиля из Японии без пробега по РФ. Гарантия на все запчасти 14 дней. Возможна замена/установка в автосервисе партнеров. /\\nПримечания: / /\\nДля упрощения поиска запчасти сообщите нам внутренний код: *3308* /\\nВ наличии на складе: 16 шт. /\\nПроверяйте соответствие данной запчасти по оригинальному номеру ОЕМ - Вашему автомобилю по VIN. Более 1000 наименований запасных частей для BMW на нашем складе в Москве. Отправляем по всей России почтой или транспортными компаниями\"'],\n",
       "       ['Сандалики Totto для мальчика',\n",
       "        'Продаю сандалики Totto для малыша! Размер 20,по стельке 12 см.'],\n",
       "       ['Фара правая Toyota RAV 4 галоген 2015-19',\n",
       "        'Фара  правая  для  Toyota  RAV4   2015/\\nОригинальный номер: 8113042650/\\nтойота рав4 тоета рав 4/\\nПроизводитель: Toyota/\\nСостояние: отличное без дефектов ! /\\nКомментарий: ПОСЛЕ 2015 НЕ КСЕНОН ГАЛОГЕН+ДИОД/\\nПожалуйста, уточняйте соответствие вашего заказа изображенному на фото. /\\nзвоните уточняйте по наличию предоставляется время на проверку детали /\\nотправляем в регионы РФ транспортными компаниями /\\n. /\\nВсегда включен вайбер вацап по вопросам !/\\nдополнительное фото по запросу'],\n",
       "       ...,\n",
       "       ['Светодиодный профильный прожектор 300Вт 3200К',\n",
       "        'Светодиодный профильный прожектор 300Вт 3200К YUESHENG YS-300Z-W./\\nНовый. В наличии 2шт./\\nСветодиодный профилирующий прожектор белого света. Цветовая температура 3200К. Ручной зум - 17°-50°./\\nУправление: DMX 512 (3 XLR) LCD дисплей/\\nРежим: мастер/слэйв/\\nКол-во каналов DMX: 3/\\nИсточник света :300W White COB LED, 3200K/\\nCRI:Ra>85LED /\\nГабариты: 62*29*22 см/\\nВес: 10кг/\\nНапряжение питания: 100-240В /50Гц/\\nПотребляемая мощность: 320Вт (макс)'],\n",
       "       ['Платье праздничное',\n",
       "        'Великолепное праздничное платье в отличном состоянии!'],\n",
       "       ['Продам производственное помещение, 90 м²',\n",
       "        'Продажа встроенного нежилого помещения рядом с м.Чкаловская на ул.Большая Зеленина. Удаленность от метро 250 м, вход со стороны улицы со двора, внутри которого можно парковаться.. Помещение площадью 90 кв.м расположено в подвале жилого дома, состоит из двух залов и входной группы, сделан ремонт, высота потолков 2,31 м, заглубление 1,3 м. Объект хорошо подходит для организации магазина, сферы услуг. Клиентам легко будет найти проход к помещению и легко добраться от метро. В настоящее время сдано в аренду под магазин костюмов. Продажа с арендатором.']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compression(array_to_compress: np.array):\n",
    "    '''\n",
    "    Function to compress sparse matrices for model fitting\n",
    "    '''\n",
    "    print('{} array in memory (raw): {:.3f} Mb'.format(str(array_to_compress), array_to_compress.nbytes * 1e-6))\n",
    "    csr = csr_matrix(array_to_compress)\n",
    "    print('{} array in memory (compressed): {:.3f} Mb'.format(\n",
    "        str(array_to_compress), (csr.data.nbytes + csr.indptr.nbytes + csr.indices.nbytes) * 1e-6\n",
    "    ))\n",
    "    return csr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-ZEdlEGAXTD"
   },
   "source": [
    "### Токенизация (0.5 балла)\n",
    "\n",
    "\n",
    "Токенизация -- разбиение текста на мелкие части, которые можно обработать машинными методами.\n",
    "Можно использовать разные алгоритмы токенизации. В данном задании мы будем использовать `WordPunctTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...\n",
      "after: ['здраствуйте', '.', 'я', ',', 'кирилл', '.', 'хотел', 'бы', 'чтобы', 'вы', 'сделали', 'игру', ',', '3д', '-', 'экшон', 'суть', 'такова', '...']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "text = 'Здраствуйте. Я, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...'\n",
    "\n",
    "print(\"before:\", text,)\n",
    "print(\"after:\", tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_RYBKC26o1X"
   },
   "source": [
    "__Задание:__ реализуйте функцию ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "O9VgNlZ1Qy3o",
    "outputId": "59ef3a75-008e-47c5-fba8-a319eba13ef4"
   },
   "outputs": [],
   "source": [
    "def preprocess(text: str, tokenizer) -> str:\n",
    "    \"\"\"\n",
    "    Данная функция принимает на вход текст, \n",
    "    а возвращает тот же текст, но с пробелами между каждым токеном\n",
    "    \"\"\"\n",
    "    \n",
    "    return ' '.join(tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert preprocess(text, tokenizer) == 'здраствуйте . я , кирилл . хотел бы чтобы вы сделали игру , 3д - экшон суть такова ...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ токенизируйте `'title'` и `'description'` в `train` и `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_array(a: np.array, tokenizer):\n",
    "    ''' \n",
    "    This function creates spaces between word entities\n",
    "    for simplification of further split() routine\n",
    "    '''\n",
    "    n1, n2 = a.shape\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            a[i][j] = preprocess(a[i][j], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5WO-7tJUvbs"
   },
   "outputs": [],
   "source": [
    "tokenize_array(X_train, tokenizer)\n",
    "tokenize_array(X_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDnDSWwFDwFo"
   },
   "outputs": [],
   "source": [
    "assert X_train[5][0] == '1 - к квартира , 33 м² , 4 / 5 эт .'\n",
    "assert X_train[10][1] == 'продам иж планета 3 , 76 год , ( стоит на старом учёте , документы утеряны ) на ходу , хорошее состояние , все интересующие вопросы по телефону ( с родной коляской на 3 тысячи дороже ) . торга не будет .'\n",
    "assert X_test[2][0] == 'фара правая toyota rav 4 галоген 2015 - 19'\n",
    "assert X_test[2][1] == 'фара правая для toyota rav4 2015 / оригинальный номер : 8113042650 / тойота рав4 тоета рав 4 / производитель : toyota / состояние : отличное без дефектов ! / комментарий : после 2015 не ксенон галоген + диод / пожалуйста , уточняйте соответствие вашего заказа изображенному на фото . / звоните уточняйте по наличию предоставляется время на проверку детали / отправляем в регионы рф транспортными компаниями / . / всегда включен вайбер вацап по вопросам !/ дополнительное фото по запросу'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlIITUk0AsmS"
   },
   "source": [
    "### BOW (3 балла)\n",
    "\n",
    "Один из традиционных подходов -- построение bag of words.\n",
    "\n",
    "Метод состоит в следующем:\n",
    "\n",
    " - Составить словарь самых часто встречающихся слов в `train data`\n",
    " - Для каждого примера из `train` посчитать, сколько раз каждое слово из словаря в нём встречается\n",
    "\n",
    "\n",
    " В `sklearn` есть `CountVectorizer`, но в этом задании его использовать нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMKUttDWIF92"
   },
   "source": [
    "__Задание:__ создайте словарь, где каждому токену соответствует количество раз, которое оно встретилось в `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_subrout(tmp: list, d: dict) -> dict:\n",
    "    '''\n",
    "    Subroutine function to count occurences\n",
    "    '''\n",
    "    for item in tmp:\n",
    "        if item in d:\n",
    "            d[item] += 1\n",
    "        else:\n",
    "            d[item] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freq_dict(a: np.array) -> dict:\n",
    "    '''\n",
    "    Function to create\n",
    "    key-value dictionary for BOW model\n",
    "    key: word, value: occurence count\n",
    "    '''\n",
    "    tokens_cnt = {}\n",
    "    n1, n2 = a.shape\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            tmp_arr = a[i][j].split()\n",
    "            tokens_cnt = dict_subrout(tmp_arr, tokens_cnt)\n",
    "    return tokens_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_cnt = create_freq_dict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tokens_cnt['сапоги'] == 454"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ выведите 10 самых частотных и 10 самых редких токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['/', '85802'],\n",
       "       [',', '79117'],\n",
       "       ['.', '65624'],\n",
       "       ...,\n",
       "       ['дооснастить', '1'],\n",
       "       ['хлебозаводская', '1'],\n",
       "       ['фрионом', '1']], dtype='<U246')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_cnt_sorted = np.array(sorted(tokens_cnt.items(), key=lambda x: x[1], reverse=True))\n",
    "tokens_cnt_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most frequent words are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      ",\n",
      ".\n",
      "-\n",
      "в\n",
      "и\n",
      "на\n",
      "./\n",
      ":\n",
      "с\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(tokens_cnt_sorted[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most rare words are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "фрионом\n",
      "хлебозаводская\n",
      "дооснастить\n",
      "беспрецедентно\n",
      "понравившейся\n",
      "объективную\n",
      "столиц\n",
      "петровского\n",
      "гремят\n",
      "шуршат\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(tokens_cnt_sorted[len(tokens_cnt_sorted) - 1 - i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ оставьте в словаре только топ-10000 самых частотных токенов, также создайте отдельный список из этих слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_cnt_top = tokens_cnt_sorted[:10000] #list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(lst: np.array) -> dict:\n",
    "    '''\n",
    "    Function to convert np.array to dictionary\n",
    "    in case it's needed in further model building\n",
    "    '''\n",
    "    tmp_dict = {}\n",
    "    for tup in lst:\n",
    "        tmp_dict[tup[0]] = tup[1] \n",
    "    return tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_cnt = convert_to_dict(tokens_cnt_top)\n",
    "tokens_list = np.array([elem[0] for elem in tokens_cnt_top])\n",
    "tokens_list_all = np.array([elem[0] for elem in tokens_cnt_sorted])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ реализуйте функцию, которая переводит текст в вектор из чисел. То есть каждому токену из списка токенов сопоставляется количество раз, которое он встретился в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4awkhecbR9om"
   },
   "outputs": [],
   "source": [
    "def text_to_bow(text: str, tokens_list: list) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из словаря\n",
    "    указано количество его употреблений в предложении\n",
    "    input: строка, список токенов\n",
    "    output: вектор той же размерности, что и список токенов\n",
    "    \"\"\"\n",
    "    bow = []\n",
    "    s_prep = preprocess(text, tokenizer)\n",
    "    tokens = s_prep.split()\n",
    "    for item in tokens_list:\n",
    "        bow.append(tokens.count(item))\n",
    "    return np.array(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    4,   12,  565,  866, 1601, 2539, 4063])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = text_to_bow(\"сдаётся уютный , тёплый гараж для стартапов в ml\", tokens_list)\n",
    "np.nonzero(example_text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = text_to_bow(\"сдаётся уютный , тёплый гараж для стартапов в ml\", tokens_list)\n",
    "\n",
    "assert np.allclose(example_text.mean(), 0.0008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код почти проходит assert и возвращаются довольно близкие индексы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ а теперь реализуйте функцию, которая преобразует наш датасет и каждому тексту из `'description'` сопоставляет вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HR_D8Fn4pudv"
   },
   "outputs": [],
   "source": [
    "def descr_to_bow(items: np.array, tokens_list: list) -> np.array:\n",
    "    \"\"\" Для каждого описания товара возвращает вектор его bow \"\"\"\n",
    "    bow_output = []\n",
    "    for i in range(items.shape[0]):\n",
    "        bow_output.append(text_to_bow(items[i][1], tokens_list))\n",
    "    return np.array(bow_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "wwOZaEpMSQsZ",
    "outputId": "8a30c3af-3517-42bd-a5f3-36206b4b264a"
   },
   "outputs": [],
   "source": [
    "X_train_bow = descr_to_bow(X_train, tokens_list)\n",
    "X_test_bow = descr_to_bow(X_test, tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['сапоги 46 размер новые', 'сапоги 46 размер новые'],\n",
       "       ['светильники потолочный swarovski',\n",
       "        'светильники потолочные swarovski 6 штук , цена за штуку . в эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n",
       "       ['iphone 7 plus 128gb red красный в наличии',\n",
       "        '/ / данная цена только для подписчиков instagram : iqmac / / новый красный айфон 7 plus в наличии это элегантный и мощный смартфон , который готов в полной мере раскрыть новые возможности ios 10 . аппарат с 4 - ядерным процессором а10 и 3 гб озу с легкостью решает самые ресурсоемкие задачи , позволяя наслаждаться быстродействием « тяжелых » приложений и игр на 5 , 5 - дюймовом дисплее . аппарат получил экран , как у ipad pro , так что картинка теперь соответствует кинематографическому стандарту .'],\n",
       "       ...,\n",
       "       ['lada kalina , 2008',\n",
       "        'всю информацию о кредитовании можно получить у сотрудников петровского автоцентра ./ / об автомобиле :/ - автомобиль приобретался у официального дилера / - 2 хозяина / - оригинал птс / - полный комплект документов / - автомобиль в родной краске / - автомобиль принят в зачёт на новый renault / / гарантированная скидка :/ - при сдаче в зачет своего автомобиля / - при покупке в кредит / / скидки суммируются !/ / петровский автоцентр , официальный дилер марки renault на протяжении 23 лет . / мы являемся лучшим дилером двух столиц ./ / все автомобили проходят подробную техническую диагностику по 75 пунктам , проверяются на юридическую чистоту и проходят предпродажную подготовку . мы предоставим вам полную и объективную информацию о состоянии автомобиля ./ приглашаем вас на проведение пробной ( ознакомительной ) поездки ! у нас вы можете проверить кузов на предмет окрашенных деталей с прибором , провести осмотр на подъемнике ./ мы готовы предложить вам полный спектр услуг : обмен вашего автомобиля с пробегом по системе trade - in , выкуп вашего автомобиля , каско , осаго , зеленая карта , диагностическая карта , постановка автомобиля на учет в гибдд . у нас вы сможете приобрести понравившейся автомобиль в кредит ( беспрецедентно низкая процентная ставка – от 1 % в месяц !). так же сможем предложить дооснастить ваш автомобиль необходимыми аксессуарами ./ мы экономим время наших клиентов , поэтому покупка автомобиля в наших дц займет у вас не более часа !/ / птс оригинал ./ / место осмотра / / осмотреть автомобиль можно по адресу : москва , мытищи , ул . хлебозаводская , 4 , петровский автоцентр мытищи / / комплектация :/ / пассивная безопасность :/ — блокировка замков задних дверей / противоугонная система :/ — сигнализация / — иммобилайзер / — центральный замок / помощь при вождении :/ — бортовой компьютер / комфорт :/ — регулировка сиденья водителя / — регулировка сиденья пассажира / управление климатом и обогрев :/ — обогрев заднего стекла / мультимедиа и навигация :/ — cd / — mp3 / — радио / — розетка 12v / салон и интерьер :/ — тканевая обивка салона / — темный салон / — складывающееся заднее сидение / экстерьер :/ — литые легкосплавные диски / освещение :/ — галогенные фары / комплектность :/ — птс / — свидетельство о регистрации / — балонный ключ / — домкрат / — полноразмерное запасное колесо'],\n",
       "       ['фреон', 'балон с фрионом'],\n",
       "       ['детская водолазка',\n",
       "        'детская водолазка . размер 3 - 4 года . б / у пару раз . цвет : тёмно - синий .']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.08800749063506\n",
      "1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(X_test_bow[0]))\n",
    "print(np.linalg.norm(X_train_bow[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train_bow.shape == (21000, 10000), X_test_bow.shape == (9000, 10000)\n",
    "assert 0.005 < X_train_bow.mean() < 0.006\n",
    "assert 0.005 < X_test_bow.mean() < 0.006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJoXiCWI7VF5"
   },
   "source": [
    "### Логистическая регрессия и SVC (0.5 балла)\n",
    "\n",
    "\n",
    "Теперь описание каждого товара представлено, как точка в многомерном пространстве.\n",
    "Очень важно запомнить эту идею: дальше мы будем рассматривать разные способы перехода от текста к точке в пространстве.\n",
    "\n",
    "Для BOW каждое измерение в пространстве -- какое-то слово.\n",
    "Мы предполагаем, что текст описывается набором каких-то популярных слов, которые в нём встречаются, а близкие по смыслу тексты будут использовать одинаковые слова.\n",
    "\n",
    "Обучите логистическую регрессию и SVM с линейным ядром (`sklearn.svm.LinearSVC` или `sklearn.svm.SVC(kernel='linear')`) с базовыми параметрами. При необходимости можете увеличить максимальное число итераций. В качестве `random_state` возьмите 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Подсказка: для того, чтобы было проще обучать, можно использовать [разреженные матрицы](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D1%80%D0%B5%D0%B6%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0) - многие модели из `sklearn` умеют с ними работать. Соответствующий модуль из `scipy`: [scipy.sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html). Нетрудно заметить, что в полученных BOW-матрицах очень много нулей. Если хранить в памяти только ненулевые элементы, можно сильно оптимизировать вычисления. Можете в этом убедиться:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  2  1 ...  0  0  0]\n",
      " [ 4  5  3 ...  0  0  0]\n",
      " ...\n",
      " [42 14  4 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  4 ...  0  0  0]] array in memory (raw): 1680.000 Mb\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  2  1 ...  0  0  0]\n",
      " [ 4  5  3 ...  0  0  0]\n",
      " ...\n",
      " [42 14  4 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  4 ...  0  0  0]] array in memory (compressed): 8.606 Mb\n"
     ]
    }
   ],
   "source": [
    "X_train_bow_csr = compression(X_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train check if sparse\n",
    "issparse(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  1  6 ...  0  0  0]\n",
      " [ 0  1  1 ...  0  0  0]\n",
      " [10  1  2 ...  0  0  0]\n",
      " ...\n",
      " [10  1  3 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  9  9 ...  0  0  0]] array in memory (raw): 720.000 Mb\n",
      "[[10  1  6 ...  0  0  0]\n",
      " [ 0  1  1 ...  0  0  0]\n",
      " [10  1  2 ...  0  0  0]\n",
      " ...\n",
      " [10  1  3 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  9  9 ...  0  0  0]] array in memory (compressed): 3.702 Mb\n"
     ]
    }
   ],
   "source": [
    "X_test_bow_csr = compression(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_bow\n",
    "del X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJVLS8Fs3CeT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "\n",
    "logreg = LogisticRegression(random_state=13, max_iter=1000)\n",
    "logreg.fit(X_train_bow_csr, y_train)\n",
    "y_pred_lg = logreg.predict(X_test_bow_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "Ky3HV1rTSS9L",
    "outputId": "612a5f0d-76bd-44f4-eeeb-63b517443797"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6966666666666667\n"
     ]
    }
   ],
   "source": [
    "#accuracy for Logistic Regression\n",
    "print(accuracy_score(y_test, y_pred_lg))\n",
    "assert accuracy_score(y_test, y_pred_lg) > 0.695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC\n",
    "\n",
    "svc = LinearSVC(random_state=13, max_iter=10000)\n",
    "svc.fit(X_train_bow_csr, y_train)\n",
    "y_pred_svc = svc.predict(X_test_bow_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "-c46ZT0lvF6T",
    "outputId": "4b1cb34a-201b-4dc2-9155-fdb6919c6c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684\n"
     ]
    }
   ],
   "source": [
    "#accuracy for LinearSVC\n",
    "print(accuracy_score(y_test, y_pred_svc))\n",
    "assert accuracy_score(y_test, y_pred_svc) > 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwKE57YZ1Hzn"
   },
   "source": [
    "### Модификация признаков (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewMlxQezL6Ax"
   },
   "source": [
    "Прибавьте к соответствующим BOW-векторам BOW-вектора для `'title'` товара с некоторым весом. Изменится ли качество? Как вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "добавляю 'title' с единичным весом; корпус становится больше и модель учитывает теперь не только наличие слов в description, но в том числе и в title, то есть BOW модель стала богаче и содержит больше вхождений тех же самых слов; ну а это в свою очередь влияет на резльутаты классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descr_to_bow_all(items: np.array, tokens_list: list) -> np.array:\n",
    "    \"\"\" \n",
    "    Для каждого описания товара возвращает вектор его bow \n",
    "    (modified for title addition)\n",
    "    \"\"\"\n",
    "    bow_output = []\n",
    "    for i in range(items.shape[0]):\n",
    "        bow_output.append(\n",
    "            np.add(text_to_bow(items[i][0], tokens_list), text_to_bow(items[i][1], tokens_list))\n",
    "    )\n",
    "    return np.array(bow_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow_all = descr_to_bow_all(X_train, tokens_list)\n",
    "X_test_bow_all = descr_to_bow_all(X_test, tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  2  1 ...  0  0  0]\n",
      " [ 4  5  3 ...  0  0  0]\n",
      " ...\n",
      " [42 15  4 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  4 ...  0  0  0]] array in memory (raw): 1680.000 Mb\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  2  1 ...  0  0  0]\n",
      " [ 4  5  3 ...  0  0  0]\n",
      " ...\n",
      " [42 15  4 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0  4 ...  0  0  0]] array in memory (compressed): 9.000 Mb\n",
      "[[10  1  6 ...  0  0  0]\n",
      " [ 0  1  1 ...  0  0  0]\n",
      " [10  1  2 ...  0  0  0]\n",
      " ...\n",
      " [10  1  3 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0 10  9 ...  0  0  0]] array in memory (raw): 720.000 Mb\n",
      "[[10  1  6 ...  0  0  0]\n",
      " [ 0  1  1 ...  0  0  0]\n",
      " [10  1  2 ...  0  0  0]\n",
      " ...\n",
      " [10  1  3 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0 10  9 ...  0  0  0]] array in memory (compressed): 3.868 Mb\n"
     ]
    }
   ],
   "source": [
    "X_train_bow_all_csr = compression(X_train_bow_all)\n",
    "X_test_bow_all_csr = compression(X_test_bow_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7787777777777778\n"
     ]
    }
   ],
   "source": [
    "#logistic regression ('Title' + 'Description')\n",
    "\n",
    "logreg = LogisticRegression(random_state=13, max_iter=1000)\n",
    "logreg.fit(X_train_bow_all_csr, y_train)\n",
    "y_pred_lg_all = logreg.predict(X_test_bow_all_csr)\n",
    "print(accuracy_score(y_test, y_pred_lg_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7535555555555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC ('Title' + 'Description')\n",
    "\n",
    "svc = LinearSVC(random_state=13, max_iter=1000)\n",
    "svc.fit(X_train_bow_all_csr, y_train)\n",
    "y_pred_svc_all = svc.predict(X_test_bow_all_csr)\n",
    "print(accuracy_score(y_test, y_pred_svc_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Db4TyqzxMnby"
   },
   "source": [
    "Нормализуйте данные с помощью `MinMaxScaler` или `MinAbsScaler` перед обучением. Что станет с качеством и почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все же `MaxAbsScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train_bow_all_csr)\n",
    "X_train_bow_all_csr_scaled = scaler.transform(X_train_bow_all_csr)\n",
    "X_test_bow_all_csr_scaled = scaler.transform(X_test_bow_all_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7191111111111111\n"
     ]
    }
   ],
   "source": [
    "#logistic regression (MaxAbsScaled)\n",
    "\n",
    "logreg = LogisticRegression(random_state=13, max_iter=1000)\n",
    "logreg.fit(X_train_bow_all_csr_scaled, y_train)\n",
    "y_pred_lg_all_scaled = logreg.predict(X_test_bow_all_csr_scaled)\n",
    "print(accuracy_score(y_test, y_pred_lg_all_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7626666666666667\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC (MaxAbsScaled)\n",
    "\n",
    "svc = LinearSVC(random_state=13, max_iter=1000)\n",
    "svc.fit(X_train_bow_all_csr_scaled, y_train)\n",
    "y_pred_svc_all_scaled = svc.predict(X_test_bow_all_csr_scaled)\n",
    "print(accuracy_score(y_test, y_pred_svc_all_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему в данном случае использовать `StandardScaler` - не очень хорошая идея?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HvCAL3qGDByj"
   },
   "source": [
    "### Иная предобработка (1 балл)\n",
    "\n",
    "**На выбор**:\n",
    "\n",
    "- **либо** обучите модели, используя для предобработки токенизатор и лемматизатор `pymystem3.Mystem`.\n",
    "- **либо** добавьте к предобработке стэмминг.\n",
    "\n",
    "Сравните полученное сейчас качество с полученным ранее и сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/nlpub/pymystem3\n",
      "  Cloning https://github.com/nlpub/pymystem3 to /private/var/folders/k6/bbc60q_546v72xm537by5d400000gn/T/pip-req-build-j0nzo0c7\n",
      "  Running command git clone -q https://github.com/nlpub/pymystem3 /private/var/folders/k6/bbc60q_546v72xm537by5d400000gn/T/pip-req-build-j0nzo0c7\n",
      "Requirement already satisfied (use --upgrade to upgrade): pymystem3==0.2.0 from git+https://github.com/nlpub/pymystem3 in /Users/ivan/anaconda3/lib/python3.7/site-packages\n",
      "Requirement already satisfied: requests in /Users/ivan/anaconda3/lib/python3.7/site-packages (from pymystem3==0.2.0) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from requests->pymystem3==0.2.0) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from requests->pymystem3==0.2.0) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from requests->pymystem3==0.2.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from requests->pymystem3==0.2.0) (1.25.8)\n",
      "Building wheels for collected packages: pymystem3\n",
      "  Building wheel for pymystem3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pymystem3: filename=pymystem3-0.2.0-py3-none-any.whl size=9920 sha256=3188504ef464e4a0047cb4640e04fcd3eed48bdfb39e24c294c34cfa17686c20\n",
      "  Stored in directory: /private/var/folders/k6/bbc60q_546v72xm537by5d400000gn/T/pip-ephem-wheel-cache-j3zhevql/wheels/72/92/6b/9521f1a0b0f77ec13f07bf5f87c50c531b1d8686cf8ad48b43\n",
      "Successfully built pymystem3\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/nlpub/pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGvNHfVsDfhq"
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem()\n",
    "X_train_mystem = np.copy(X_train) # create copies to not modify initial array\n",
    "X_test_mystem = np.copy(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"[^\\w\\s]\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_string(s: str, regex: str, mystem) -> str:\n",
    "    '''\n",
    "    Function clears text from excess punctuation\n",
    "    '''\n",
    "    s = re.sub(regex, \"\", s)\n",
    "    l = mystem.lemmatize(s)\n",
    "    return ''.join(l).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_freq_dict(a: np.array, regex: str, mystem) -> dict:\n",
    "    '''\n",
    "    Function creates lemmas of words and returns BOW-dictionary\n",
    "    key: lemma, value: occurence count\n",
    "    '''\n",
    "    tokens_cnt = {}\n",
    "    n1, n2 = a.shape\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            tmp_arr = clear_string(a[i][j], regex, mystem).split()\n",
    "            tokens_cnt = dict_subrout(tmp_arr, tokens_cnt)\n",
    "    return tokens_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict_mystem = lemmatize_freq_dict(X_train, regex, mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list_mystem = [key for key in freq_dict_mystem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_stem(a: np.array) -> np.array:\n",
    "    '''\n",
    "    Function transforms initial array to lemmatized\n",
    "    '''\n",
    "    n1, n2 = a.shape\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            a[i][j] = clear_string(a[i][j], regex, mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['винт сдвижной панель потолок бмв х5 е53',\n",
       "        '3308  винт сдвижной панель потолок oem  54107199476  54 10 7 199 476    запчасть б  у в хороший состояние для bmw x5 e53   демонтировать с автомобиль из япония без пробег по рф  гарантия на весь запчасть 14 день  возможный замена  установка в автосервис партнер   примечание    для упрощение поиск запчасть сообщать мы внутренний код   3308   в наличие на склад  16 шт   проверять соответствие данный запчасть по оригинальный номер оем  ваш автомобиль по vin  более 1000 наименование запасной часть для bmw на наш склад в москва  отправлять по весь россия почта или транспортный компания'],\n",
       "       ['сандалик totto для мальчик',\n",
       "        'продавать сандалик totto для малыш  размер 20  по стелька 12 см'],\n",
       "       ['фара правый toyota rav 4 галоген 2015  19',\n",
       "        'фара правый для toyota rav4 2015  оригинальный номер  8113042650  тойота рав4 тоета рав 4  производитель  toyota  состояние  отличный без дефект   комментарий  после 2015 не ксенон галоген  диод  пожалуйста  уточнять соответствие ваш заказ изображать на фото   звонить уточнять по наличие предоставляться время на проверка деталь  отправлять в регион рф транспортный компания    всегда включать вайбер вацап по вопрос  дополнительный фото по запрос'],\n",
       "       ...,\n",
       "       ['светодиодный профильный прожектор 300вт 3200к',\n",
       "        'светодиодный профильный прожектор 300вт 3200к yuesheng ys  300z  w  новый  в наличие 2шт  светодиодный профилирующий прожектор белый свет  цветовой температура 3200к  ручной зум  17  50  управление  dmx 512  3 xlr  lcd дисплей  режим  мастер  слэйв  кол  во канал dmx  3  источник свет  300w white cob led  3200k  cri  ra  85led  габарит  62  29  22 см  вес  10кг  напряжение питание  100  240в  50гц  потреблять мощность  320вт  макс'],\n",
       "       ['платье праздничный',\n",
       "        'великолепный праздничный платье в отличный состояние'],\n",
       "       ['продавать производственный помещение  90 м²',\n",
       "        'продажа встроенный нежилой помещение рядом с м  чкаловский на ул  большой зеленин  удаленность от метро 250 м  вход со сторона улица со двор  внутри который можно парковаться  помещение площадь 90 кв  м располагать в подвал жилой дом  состоять из два зал и входной группа  сделать ремонт  высота потолок 2  31 м  заглубление 1  3 м  объект хорошо подходить для организация магазин  сфера услуга  клиент легко быть находить проход к помещение и легко добираться от метро  в настоящий время сдавать в аренда под магазин костюм  продажа с арендатор']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_stem(X_train_mystem)\n",
    "prepare_stem(X_test_mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow_mystem = descr_to_bow(X_train_mystem, tokens_list_mystem)\n",
    "X_test_bow_mystem = descr_to_bow(X_test_mystem, tokens_list_mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 0]] array in memory (raw): 9370.200 Mb\n",
      "[[1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 1 ... 0 0 0]] array in memory (compressed): 8.837 Mb\n"
     ]
    }
   ],
   "source": [
    "X_train_bow_mystem_csr = compression(X_train_bow_mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] array in memory (raw): 4015.800 Mb\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] array in memory (compressed): 3.705 Mb\n"
     ]
    }
   ],
   "source": [
    "X_test_bow_mystem_csr = compression(X_test_bow_mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7252222222222222\n"
     ]
    }
   ],
   "source": [
    "#logistic regression (mystem)\n",
    "\n",
    "logreg = LogisticRegression(random_state=13, max_iter=1000)\n",
    "logreg.fit(X_train_bow_mystem_csr, y_train)\n",
    "y_pred_lg_stem = logreg.predict(X_test_bow_mystem_csr)\n",
    "print(accuracy_score(y_test, y_pred_lg_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7128888888888889\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC (mystem)\n",
    "\n",
    "svc = LinearSVC(random_state=13, max_iter=10000)\n",
    "svc.fit(X_train_bow_mystem_csr, y_train)\n",
    "y_pred_svc_stem = svc.predict(X_test_bow_mystem_csr)\n",
    "print(accuracy_score(y_test, y_pred_svc_stem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXbsPtpfoB7m"
   },
   "source": [
    "### TF-IDF (5 баллов)\n",
    "\n",
    "Не все слова полезны одинаково, давайте попробуем [взвесить](http://tfidf.com/) их, чтобы отобрать более полезные.\n",
    "\n",
    "\n",
    "> TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "> \n",
    "> IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "\n",
    "В `sklearn` есть `TfidfVectorizer`, но в этом задании его использовать нельзя. Для простоты посчитайте общий tf-idf для `'title'` и `'description'` (то есть каждому объекту надо сопоставить вектор, где как документ будет рассматриваться конкатенация `'title'` и `'description'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ составьте словарь, где каждому слову из изначального списка будет соответствовать количество документов из `train`-части, где это слово встретилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dict(tmp: set, df_dict: dict):\n",
    "    '''\n",
    "    Supply function to count df (document frequency)\n",
    "    measure for each word in corpus\n",
    "    '''\n",
    "    for word in tmp:\n",
    "        if word in df_dict:\n",
    "            df_dict[word] += 1\n",
    "        else:\n",
    "            df_dict[word] = 1\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_dict(sample: np.array) -> dict:\n",
    "    '''\n",
    "    Function creates df dictionary\n",
    "    '''\n",
    "    df_dict = {}\n",
    "    n1, n2 = sample.shape\n",
    "    for i in range(n1):\n",
    "        tmp = []\n",
    "        for j in range(n2):\n",
    "            tmp += sample[i][j].split()\n",
    "        tmp = set(tmp)\n",
    "        df_dict = add_to_dict(tmp, df_dict)\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_document_cnt = create_df_dict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert word_document_cnt['размер'] == 2839"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ реализуйте функцию, где тексту в соответствие ставится tf-idf вектор. Для вычисления IDF также необходимо число документов в `train`-части (параметр `n_documents_total`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6i5zFpD9rbtz"
   },
   "outputs": [],
   "source": [
    "def text_to_tfidf(text: str, word_document_cnt: dict, tokens_list: list, n_documents_total: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из словаря\n",
    "    указан tf-idf\n",
    "    \"\"\"\n",
    "    tf_idf_vec = []\n",
    "    tokens = text.split()\n",
    "    for word in tokens_list:\n",
    "        tf_tmp = tokens.count(word) / len(tokens) # tf\n",
    "        idf_tmp = np.log(n_documents_total / word_document_cnt[word]) # idf\n",
    "        tf_idf_tmp = tf_tmp * idf_tmp # tf-idf\n",
    "        tf_idf_vec.append(tf_idf_tmp)\n",
    "    return np.array(tf_idf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = text_to_tfidf(\n",
    "    'сдаётся уютный , тёплый гараж для стартапов в ml',\n",
    "    word_document_cnt,\n",
    "    tokens_list,\n",
    "    n_documents_total=len(X_train)\n",
    ")\n",
    "assert np.allclose(np.linalg.norm(example_text), 1.4435668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = text_to_tfidf(\n",
    "    'сдаётся уютный , тёплый гараж для стартапов в ml',\n",
    "    word_document_cnt,\n",
    "    tokens_list,\n",
    "    n_documents_total=len(X_train)\n",
    ")\n",
    "assert 0.0003 < example_text.mean() < 0.0004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ а теперь реализуйте функцию, которая преобразует наш датасет и для каждого объекта сопоставляет вектор tf-idf. В качестве текстов используйте конкатенацию `'title'` и `'description'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_to_tfidf(items: np.array, word_document_cnt: dict, tokens_list: list, n_documents_total: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Для каждого товара возвращает его tf-idf вектор\n",
    "    \"\"\"\n",
    "    tf_idf_items = []\n",
    "    n1, n2 = items.shape\n",
    "    for i in range(n1):\n",
    "        tmp = []\n",
    "        for j in range(n2):\n",
    "            tmp += items[i][j].split()\n",
    "        tmp_str = ' '.join(tmp)\n",
    "        tf_idf_tmp = text_to_tfidf(tmp_str, word_document_cnt, tokens_list, n_documents_total)\n",
    "        tf_idf_items.append(tf_idf_tmp)\n",
    "    return np.array(tf_idf_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = items_to_tfidf(X_train, word_document_cnt, tokens_list, len(X_train))\n",
    "X_test_tfidf = items_to_tfidf(X_test, word_document_cnt, tokens_list, len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train_tfidf.shape == (21000, 10000), X_test_tfidf.shape == (9000, 10000)\n",
    "assert 0.0002 < X_train_tfidf.mean() < 0.0004\n",
    "assert 0.0002 < X_test_tfidf.mean() < 0.0004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YFA-8kE1RHk"
   },
   "source": [
    "__Задание:__ обучите логистическую регрессию и SVC, оцените качество (accuracy_score). Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.02780371 0.01110134 ... 0.         0.         0.        ]\n",
      " [0.03384833 0.01882543 0.00901984 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.08529778 0.01355431 0.00288635 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.03531999 0.         0.05019738 ... 0.         0.         0.        ]] array in memory (raw): 1680.000 Mb\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.02780371 0.01110134 ... 0.         0.         0.        ]\n",
      " [0.03384833 0.01882543 0.00901984 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.08529778 0.01355431 0.00288635 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.03531999 0.         0.05019738 ... 0.         0.         0.        ]] array in memory (compressed): 9.000 Mb\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf_csr = compression(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06396534 0.00284605 0.01363629 ... 0.         0.         0.        ]\n",
      " [0.         0.02008046 0.01603527 ... 0.         0.         0.        ]\n",
      " [0.09127638 0.00406122 0.00648618 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.07385089 0.00328589 0.00787186 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.03227216 0.02319388 ... 0.         0.         0.        ]] array in memory (raw): 720.000 Mb\n",
      "[[0.06396534 0.00284605 0.01363629 ... 0.         0.         0.        ]\n",
      " [0.         0.02008046 0.01603527 ... 0.         0.         0.        ]\n",
      " [0.09127638 0.00406122 0.00648618 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.07385089 0.00328589 0.00787186 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.03227216 0.02319388 ... 0.         0.         0.        ]] array in memory (compressed): 3.868 Mb\n"
     ]
    }
   ],
   "source": [
    "X_test_tfidf_csr = compression(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-c98c27840f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "del X_train_tfidf\n",
    "del X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression (tf-idf)\n",
    "\n",
    "logreg = LogisticRegression(random_state=13, max_iter=1000)\n",
    "logreg.fit(X_train_tfidf_csr, y_train)\n",
    "y_pred_lg = logreg.predict(X_test_tfidf_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ULrXsF1m5sU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6795555555555556\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_lg))\n",
    "assert accuracy_score(y_test, y_pred_lg) > 0.675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearSVC (tf-idf)\n",
    "\n",
    "svc = LinearSVC(random_state=13, max_iter=1000)\n",
    "svc.fit(X_train_tfidf_csr, y_train)\n",
    "y_pred_svc = svc.predict(X_test_tfidf_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7942222222222223\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_svc))\n",
    "assert accuracy_score(y_test, y_pred_svc) > 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vQZ61xSsTpZI"
   },
   "source": [
    "### Word Vectors (4 балла)\n",
    "\n",
    "Давайте попробуем другой подход -- каждому слову сопоставим какое-то векторное представление (эмбеддинг) - но достаточно маленькой размерности. Таким образом мы сильно уменьшим количество параметров в модели.\n",
    "\n",
    "Почитать про это подробнее можно тут:\n",
    "\n",
    "- https://habr.com/ru/company/ods/blog/329410/\n",
    "\n",
    "Вектора мы возьмём уже готовые (обученные на текстах из интернета), так что наша модель будет знать некоторую дополнительную информацию о внешнем мире."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "id": "T38J27NcYGx5",
    "outputId": "57fa3a9f-13a3-4fa1-d13c-3c0c49a86a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to set locale category LC_NUMERIC to en_RU.\n",
      "Warning: Failed to set locale category LC_TIME to en_RU.\n",
      "Warning: Failed to set locale category LC_COLLATE to en_RU.\n",
      "Warning: Failed to set locale category LC_MONETARY to en_RU.\n",
      "Warning: Failed to set locale category LC_MESSAGES to en_RU.\n",
      "--2020-04-14 22:04:34--  https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/0x7oxso6x93efzj/ru.tar.gz [following]\n",
      "--2020-04-14 22:04:34--  https://www.dropbox.com/s/raw/0x7oxso6x93efzj/ru.tar.gz\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc50eea3dc4101610521716931a8.dl.dropboxusercontent.com/cd/0/inline/A12E-ehkrSTpnC4u4y03whOPrmC9fcDwvF_zSVvbls4L73negGxLCph5WBCXBfiQMW6ww7d3d6WE8smXjyH0IHsQnMxD_9kR1Bgta1Cem7OZyA/file# [following]\n",
      "--2020-04-14 22:04:35--  https://uc50eea3dc4101610521716931a8.dl.dropboxusercontent.com/cd/0/inline/A12E-ehkrSTpnC4u4y03whOPrmC9fcDwvF_zSVvbls4L73negGxLCph5WBCXBfiQMW6ww7d3d6WE8smXjyH0IHsQnMxD_9kR1Bgta1Cem7OZyA/file\n",
      "Resolving uc50eea3dc4101610521716931a8.dl.dropboxusercontent.com (uc50eea3dc4101610521716931a8.dl.dropboxusercontent.com)... 162.125.70.6\n",
      "Connecting to uc50eea3dc4101610521716931a8.dl.dropboxusercontent.com (uc50eea3dc4101610521716931a8.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: /cd/0/inline2/A12W7Gnsr6ilfEkjeFR5KQMpk0Vbu60OLKK6NH9RryT9MrMLiO6v7kv79LEBxEgSfzP_zX5ahzDuoOkC_Z44gkORY8fuug9CPz40BRmJTAVDdLJqL-zMTnVIbYutpsotft1C88f4gb2kaC2E-uHfhuaVJdkjLP2zfAYstgN_C298ojnaM-WYEw1v8HlBVn3hoLnGPz7L0dLMgmTWvCkvd9544Yzd0eyMFMp589F2FYVIts3ok_dPEr2cWhnlR1BoqimFvCQSmXyp0tKxx6Kcdj2LJPH-3KHOdzDH04DYvdmv203-QTvv1G0iSL5LIeIBcoXLqie1_hJRkAm_h-vnj5J8/file [following]\n",
      "--2020-04-14 22:04:36--  https://uc50eea3dc4101610521716931a8.dl.dropboxusercontent.com/cd/0/inline2/A12W7Gnsr6ilfEkjeFR5KQMpk0Vbu60OLKK6NH9RryT9MrMLiO6v7kv79LEBxEgSfzP_zX5ahzDuoOkC_Z44gkORY8fuug9CPz40BRmJTAVDdLJqL-zMTnVIbYutpsotft1C88f4gb2kaC2E-uHfhuaVJdkjLP2zfAYstgN_C298ojnaM-WYEw1v8HlBVn3hoLnGPz7L0dLMgmTWvCkvd9544Yzd0eyMFMp589F2FYVIts3ok_dPEr2cWhnlR1BoqimFvCQSmXyp0tKxx6Kcdj2LJPH-3KHOdzDH04DYvdmv203-QTvv1G0iSL5LIeIBcoXLqie1_hJRkAm_h-vnj5J8/file\n",
      "Reusing existing connection to uc50eea3dc4101610521716931a8.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2399456034 (2.2G) [application/octet-stream]\n",
      "Saving to: ‘ru.tar.gz.1’\n",
      "\n",
      "ru.tar.gz.1         100%[===================>]   2.23G  6.00MB/s    in 5m 33s  \n",
      "\n",
      "2020-04-14 22:10:10 (6.87 MB/s) - ‘ru.tar.gz.1’ saved [2399456034/2399456034]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz\n",
    "# если не работает (возможно, у вас windows) - можете скачать файл по соответствующей ссылке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zfse4xVbgMIr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru.bin: (Empty error message)\r\n",
      "tar: Error exit delayed from previous errors.\r\n"
     ]
    }
   ],
   "source": [
    "!tar -xzf ru.tar.gz\n",
    "# распаковка файла - опять же, если не работает, распакуйте вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/ivan/anaconda3/lib/python3.7/site-packages (3.8.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: requests in /Users/ivan/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: boto3 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.12.39)\n",
      "Requirement already satisfied: boto in /Users/ivan/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.1)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.39 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.15.39)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.5)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/ivan/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.39->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sy2TXmQ2jZSY"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.wrappers import FastText\n",
    "\n",
    "embedding_model = FastText.load_fasttext_format('ru.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "[ 0.02916384  0.02167605  0.05127367 -0.00971958  0.0465235  -0.03945766\n",
      "  0.02737866  0.00638128 -0.03774629 -0.04257201 -0.00995653  0.02291315\n",
      " -0.02301722  0.06697998 -0.03674482 -0.02403202 -0.05404469  0.01372932\n",
      "  0.00926399 -0.0013149   0.11941359 -0.022448    0.04011497  0.06980549\n",
      "  0.00407011 -0.09384539  0.03050164 -0.02578281 -0.03525181 -0.06603175\n",
      "  0.04752798  0.05874675  0.01983666  0.06092105 -0.00957561  0.08307806\n",
      " -0.01288903  0.04705157  0.02198839 -0.00649013 -0.0171444   0.03302203\n",
      "  0.02124882 -0.01902875 -0.05235172  0.03458685 -0.01409259 -0.07477519\n",
      "  0.01916078  0.02985001  0.0086322   0.03051201  0.02831862  0.04549561\n",
      "  0.00761138 -0.05459622  0.09056009 -0.08807947 -0.05420396 -0.04793203\n",
      " -0.05672329 -0.03025264 -0.03024072 -0.05890108 -0.03137474  0.03292617\n",
      "  0.05440779 -0.04548327 -0.07266086 -0.09327219  0.07247883  0.0111061\n",
      "  0.01824225 -0.10570452  0.05110046 -0.04659343 -0.03277056 -0.00803401\n",
      " -0.03978698  0.00826598 -0.01074128  0.018431   -0.10150263 -0.00472604\n",
      "  0.06706332  0.02466901  0.09045192 -0.05226929  0.04866098 -0.02843297\n",
      "  0.04756537  0.00261342  0.06845197  0.00082511 -0.00547984  0.0100649\n",
      "  0.02135489 -0.01437242  0.00191435  0.11989547  0.02357679  0.07061605\n",
      "  0.03375214  0.05462346  0.08270866  0.00126649  0.03054527  0.04314573\n",
      " -0.00719835 -0.02799017  0.00249404  0.00139046 -0.04099929  0.00526204\n",
      "  0.01386764  0.02106066  0.00887202  0.05943111 -0.07185322  0.03263306\n",
      "  0.00284878  0.03816929  0.0210096  -0.030828    0.00502779  0.09250114\n",
      "  0.02399154  0.05744717 -0.04319151  0.04075926 -0.03877947  0.0605263\n",
      " -0.00837917 -0.04922852 -0.04570796  0.02973622 -0.01798053  0.00413011\n",
      " -0.00712464 -0.01312802  0.05847022 -0.07881333 -0.02204878  0.03086594\n",
      "  0.02965177 -0.0073295  -0.02443145 -0.06222062  0.01083152  0.06009534\n",
      " -0.02042049  0.06301811  0.02287635 -0.03021961  0.04831248  0.02882019\n",
      "  0.04446645 -0.01677353 -0.08272323 -0.06830658  0.08947854  0.03370909\n",
      " -0.00895046 -0.00681254 -0.02059644 -0.09527113  0.02611189 -0.06112244\n",
      "  0.01080315  0.01901113  0.00810233  0.00742132  0.10493557 -0.00522375\n",
      "  0.05826566  0.03236291  0.03787734 -0.05026894 -0.08401242  0.02860721\n",
      " -0.05106218  0.02631241  0.02631763  0.06924202  0.03319636  0.00980412\n",
      "  0.04016861  0.03428936  0.00652957 -0.01058654 -0.0245588   0.1464914\n",
      " -0.01041028  0.03553488 -0.07482928 -0.01063148 -0.0342233  -0.01662586\n",
      " -0.00029508  0.04694034 -0.00062491 -0.0435293  -0.01315623  0.07061336\n",
      "  0.01603698  0.02374655  0.05453315  0.00253603 -0.0313729  -0.02740866\n",
      "  0.04278845 -0.00810288  0.03973977  0.07674816  0.04658518 -0.02685211\n",
      " -0.05009724  0.0060723  -0.04231661  0.02584185 -0.03419575 -0.03799306\n",
      "  0.06701688 -0.1245426   0.03846397 -0.0855662  -0.01193651  0.04968415\n",
      "  0.03559558  0.10029506  0.05714916  0.01145345 -0.03564315 -0.00924199\n",
      "  0.08630151  0.08049053  0.05822275 -0.05224873 -0.02462301  0.05832206\n",
      " -0.04124978  0.00186134  0.00782246  0.01179015 -0.02291097  0.00614069\n",
      "  0.01782681  0.02190027  0.04341367  0.06151633 -0.01183114 -0.00141502\n",
      "  0.06193598  0.0611085  -0.02373199 -0.05797793 -0.02269631  0.11511736\n",
      " -0.04581353 -0.05082048 -0.04706197  0.0429772   0.00409648 -0.0141248\n",
      "  0.01417164  0.00575812 -0.07616108 -0.01051838  0.05149659  0.02367133\n",
      "  0.00073724  0.05957585 -0.11871962  0.03876314  0.03472188 -0.02344368\n",
      " -0.01165281 -0.01397923  0.08815268  0.03459521  0.07113555 -0.03984846\n",
      " -0.01600395  0.01932258  0.01351069 -0.06409036 -0.02024848  0.05895981\n",
      "  0.02591374 -0.04027611  0.00654722  0.05093394 -0.02461737  0.02561689\n",
      " -0.01412898 -0.00366109 -0.06719207  0.00742674 -0.02095614 -0.06263787]\n"
     ]
    }
   ],
   "source": [
    "# как мы видим, каждому слову данная модель сопоставляет вектор размерности 300\n",
    "\n",
    "print(embedding_model['привет'].shape)\n",
    "print(embedding_model['привет'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ реализуйте функцию, выдающую эмбеддинг для предложения - как сумму эмбеддингов токенов."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Здесь стало происходить, что-то непонятное, потому что часто для слов (например, точно для английских или каких-либо странных аббревиатур) не находились n-gram вектора. Хотя у других ребят обращаться по ключу получалось. Я сидел на форумах и читал, что по идее gensim 3.8.2 точно должен выдавать n-gram вектора и для несуществующих ключей. Например, я использовал (здесь этого нет), потому что там совершенно другие n-gram'ы load_facebook_vectors() из модуля gensim.models, откуда импортирован fasttext и у меня все работало. Короче, я не понял, что произошло и если токена нет в словаре предобученной модели, то я просто это игнорировал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H49QR_jhjmCa"
   },
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence: str, embedding_model) -> np.array:\n",
    "    \"\"\"\n",
    "    Складывает вектора токенов строки sentence\n",
    "    \"\"\"\n",
    "    sentence = re.sub(regex, '', sentence)\n",
    "    tokens = sentence.split()\n",
    "    s = np.zeros(300, )\n",
    "    for token in tokens:\n",
    "        if token in embedding_model.wv.vocab:\n",
    "            s += embedding_model[token]\n",
    "        else:\n",
    "            s += np.zeros(300, )\n",
    "    return np.array(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gj6U_hjtlllV",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-7e75adc25482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0msentence_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'сдаётся уютный , тёплый гараж для стартапов в ml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'сдаётся уютный , тёплый гараж для стартапов в ml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2.6764746\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml', embedding_model).shape == (300,)\n",
    "assert np.linalg.norm(sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml', embedding_model)) == 2.6764746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1345817719976847"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml', embedding_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание:__ сделайте все то же, что в предыдущих пунктах -- реализуйте функцию, которая преобразует данные, а затем обучите логистическую регрессию и SVM, оцените качество. Сделайте вывод, что работает лучше - модель, основанная на TF-IDF, или модель, обученная на предобученных эмбеддингах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tfhc-PFmGvu"
   },
   "outputs": [],
   "source": [
    "def text_to_embedded(items: np.array, embedding_model) -> np.array:\n",
    "    out = []\n",
    "    n1, n2 = items.shape\n",
    "    for i in range(n1):\n",
    "        out.append(\n",
    "            np.add(sentence_embedding(items[i][0], embedding_model), sentence_embedding(items[i][1], embedding_model))\n",
    "        )\n",
    "    return np.array(out)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embedded = text_to_embedded(X_train, embedding_model)\n",
    "X_test_embedded = text_to_embedded(X_test, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_embed = LogisticRegression(max_iter=1000)\n",
    "logreg_embed.fit(X_train_embedded, y_train)\n",
    "y_pred_embed = logreg_embed.predict(X_test_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.579\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred_embed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "svc_embed  = LinearSVC(max_iter=10000)\n",
    "svc_embed.fit(X_train_embedded, y_train)\n",
    "y_pred_embed_svc = svc_embed.predict(X_test_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.567\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred_embed_svc, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy больше в tfidf, поэтому tfidf более точно помогает решить задачу классификации, нежели предобученные эмбеддинги. Так получилось, что довольно много слов не находятся в эмбеддинг словаре, поэтому они входят в модель с нулевым весом и никак не учитывается. Tfidf же опирается исключительно на корпус (то есть title + description), поэтому довольно хорошо работает в рамках такой задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cVEdlFostSnX"
   },
   "source": [
    "### Что дальше? (8 баллов)\n",
    "\n",
    "Для получения максимальной оценки вам нужно решить любые 2 пункта. Решение каждого пункта даст вам полтора балла:\n",
    "\n",
    "1. Реализовать n-gram модели текстовой классификации (__2 балла__)\n",
    "\n",
    "2. Поработать с другими эмбеддингами для слов (например `word2vec` или `GloVe`) (__2 балла__)\n",
    "\n",
    "3. Применить другие способы токенизации (например, `pymorphy2`, `spaCy`) и в целом предобработки данных (стоп-слова, стэмминг, лемматизация) (__2 балла__)\n",
    "\n",
    "4. Добиться качества > 0.82 на тестовых данных (попробуйте другие токенизаторы, предобработку текста, и любые другие идеи, которые вам придут в голову) (__2 балла__)\n",
    "\n",
    "Снабжайте код пояснениями и графиками.\n",
    "Обязательно необходимо написать вывод по каждому пункту, который вы реализуете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 N-gram model (было влом и получилась полная ерунда)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ivan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gram = np.copy(X_train)\n",
    "X_test_gram = np.copy(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_stem(X_train_gram)\n",
    "prepare_stem(X_test_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_rus = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(items: np.array) -> np.array:\n",
    "    n1, n2 = items.shape\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            tokens = items[i][j].split()\n",
    "            items[i][j] = ' '.join([token for token in tokens if token not in stopwords_rus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_stopwords(X_train_gram)\n",
    "#remove_stopwords(X_test_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svc = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(preprocessor = lambda x: x)),\n",
    "    (\"svc\", LinearSVC(random_state=13))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"tfidf__ngram_range\": [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "    \"tfidf__max_df\": (0.25, 0.5, 0.75, 1.0),\n",
    "    \"svc__penalty\": ['l1', 'l2'],\n",
    "    \"svc__C\": [0.5, 1.0, 2.0, 3.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=2)]: Done 384 out of 384 | elapsed:   21.6s finished\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-8afeede0e2c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_svc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_gram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \"\"\"\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \"\"\"\n\u001b[1;32m   1858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1220\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline_svc, param_grid, cv=3, n_jobs=2, verbose=3)\n",
    "grid_search.fit(X_train_gram, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tfidf',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                  dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                  input='content', lowercase=True, max_df=0.25, max_features=None,\n",
       "                  min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                  preprocessor=<function <lambda> at 0x1a2055fdd0>,\n",
       "                  smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                  sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                  tokenizer=<function <lambda> at 0x1a2055fe60>, use_idf=True,\n",
       "                  vocabulary=None)),\n",
       " ('svc',\n",
       "  LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "            intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "            multi_class='ovr', penalty='l2', random_state=13, tol=0.0001,\n",
       "            verbose=0))]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gram = grid_search.predict(X_test_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3501111111111111\n"
     ]
    }
   ],
   "source": [
    "print(\"{}\".format(accuracy_score(y_pred_gram, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем добиться улучшения качества на тестовых данных (используя лемматизатор mystem и tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_doc_cnt_mystem = create_df_dict(X_train_mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_mystem = items_to_tfidf(X_train_mystem, word_doc_cnt_mystem, tokens_list_mystem, len(X_train_mystem))\n",
    "X_test_tfidf_mystem = items_to_tfidf(X_test_mystem, word_doc_cnt_mystem, tokens_list_mystem, len(X_train_mystem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.07146276 0.99589254 0.43431782 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.03579956 0.03579956 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         2.48806943]\n",
      " [0.         0.         0.11581809 ... 0.         0.         0.        ]] array in memory (raw): 9370.200 Mb\n",
      "[[1.07146276 0.99589254 0.43431782 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.03579956 0.03579956 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         2.48806943]\n",
      " [0.         0.         0.11581809 ... 0.         0.         0.        ]] array in memory (compressed): 9.253 Mb\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf_mystem_csr = compression(X_train_tfidf_mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.11581809 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]] array in memory (raw): 4015.800 Mb\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.11581809 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]] array in memory (compressed): 3.868 Mb\n"
     ]
    }
   ],
   "source": [
    "X_test_tfidf_mystem_csr = compression(X_test_tfidf_mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7584444444444445\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression (mystem + tf-idf)\n",
    "\n",
    "logreg = LogisticRegression(random_state=13, max_iter=1000)\n",
    "logreg.fit(X_train_tfidf_mystem_csr, y_train)\n",
    "y_pred_lg_tfidf_mystem = logreg.predict(X_test_tfidf_mystem_csr)\n",
    "print(accuracy_score(y_test, y_pred_lg_tfidf_mystem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8257777777777778\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC (mystem + tf-idf)\n",
    "\n",
    "svc = LinearSVC(random_state=13, max_iter=1000)\n",
    "svc.fit(X_train_tfidf_mystem_csr, y_train)\n",
    "y_pred_svc_tfidf_mystem = svc.predict(X_test_tfidf_mystem_csr)\n",
    "print(accuracy_score(y_test, y_pred_svc_tfidf_mystem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
